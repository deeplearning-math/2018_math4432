{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "np.random.seed(117)\n",
    "modelSaveDir = 'model/'\n",
    "if not os.path.exists(modelSaveDir):\n",
    "    os.mkdir(modelSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_affnist import loadmat\n",
    "Xtrain = []\n",
    "ytrain = []\n",
    "for i in range(1,33):\n",
    "    mat = loadmat('data/training_and_validation_batches/' + str(i) + '.mat')\n",
    "    Xtrain.append(mat['affNISTdata']['image'].T)\n",
    "    ytrain.append(mat['affNISTdata']['label_int'])\n",
    "X_train = np.vstack(Xtrain)\n",
    "y_train = np.vstack(ytrain)\n",
    "y_train = y_train.reshape((y_train.shape[0] * y_train.shape[1],))\n",
    "testDICT = loadmat('data/test.mat')\n",
    "X_test = testDICT['affNISTdata']['image'].T\n",
    "y_test = testDICT['affNISTdata']['label_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1920000, 1600), (1920000,), (320000, 1600), (320000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label = np.unique(y_test)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1600))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1600))\n",
    "X_train = X_train.astype('float32')/255.\n",
    "X_test = X_test.astype('float32')/255.\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def classify(X_train, X_test, y_train, y_test, classifier):\n",
    "    if classifier == \"lda\":\n",
    "        clf = LDA()\n",
    "    elif classifier == \"qda\":\n",
    "        clf = QDA()\n",
    "    elif classifier == \"logreg\":\n",
    "        clf = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print(pred[:10])\n",
    "    cfmtx = confusion_matrix(y_test, pred)\n",
    "    df = pd.DataFrame(cfmtx, columns=label, index=label)\n",
    "    df.columns.name = 'pred\\\\true'\n",
    "    print(df)\n",
    "    prfs = precision_recall_fscore_support(y_test, pred, average='macro')\n",
    "    print('precision:', prfs[0], '\\nrecall:', prfs[1], '\\nfscore:', prfs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0660637ebb00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# LDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-bd3aa6525d5c>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(X_train, X_test, y_train, y_test, classifier)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"logreg\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shrinkage not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lsqr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve_lsqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinkage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36m_solve_svd\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfac\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# SVD of centered (within)scaled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/linalg/decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# perform decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0;32m--> 129\u001b[0;31m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "classify(X_train, X_test, y_train, y_test, 'lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDA\n",
    "classify(X_train, X_test, y_train, y_test, 'qda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "classify(X_train, X_test, y_train, y_test, 'logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the variance to determine the components in pca \n",
    "var_ladder =[]\n",
    "for i in range(15):\n",
    "    var_ladder.append(0.2+i*0.05)\n",
    "var_ladder_output = ['%.2f' % elem for elem in var_ladder]\n",
    "print(var_ladder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca_data(X_train,X_test,var_explained):\n",
    "    pca=PCA(svd_solver='randomized',whiten=True)\n",
    "    pca.fit(X_train)\n",
    "    var=np.cumsum(pca.explained_variance_ratio_)\n",
    "    pca=PCA(np.argwhere(var>var_explained)[0][0],svd_solver='randomized',whiten=True)\n",
    "    pca.fit(X_train)\n",
    "    X_pca_train=pca.transform(X_train)\n",
    "    X_pca_test=pca.transform(X_test)\n",
    "    return X_pca_train, X_pca_test\n",
    "\n",
    "X_train_list = []\n",
    "X_test_list = []\n",
    "for var in var_ladder:\n",
    "    X_train_current, X_test_current = pca_data(X_train,X_test,var)\n",
    "    X_train_list.append(X_train_current)\n",
    "    X_test_list.append(X_test_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the intermediate result since the cell above is toooooooooooo slow!\n",
    "import pickle\n",
    "with open(\"pca_training.pkl\",\"wb\") as handle:\n",
    "    pickle.dump(X_train_list,handle)\n",
    "with open(\"pca_testing.pkl\",\"wb\") as handle:\n",
    "    pickle.dump(X_test_list,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for calculating accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "def score(X_train, X_test, y_train, y_test, classifier):\n",
    "    if classifier == \"lda\":\n",
    "        clf = LDA()\n",
    "    elif classifier == \"qda\":\n",
    "        clf = QDA()\n",
    "    elif classifier == \"logreg\":\n",
    "        clf = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    return accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printlist(list):\n",
    "    for i in list:\n",
    "        print(i,end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA: accuracy ~ total-variance-explained\n",
    "lda_accuracies = []\n",
    "for i in range(15):\n",
    "    acc = score(X_train_list[i],X_test_list[i],y_train,y_test,'lda')\n",
    "    lda_accuracies.append(acc)\n",
    "printlist(lda_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDA: accuracy ~ total-variance-explained\n",
    "qda_accuracies = []\n",
    "for i in range(15):\n",
    "    acc = score(X_train_list[i],X_test_list[i],y_train,y_test,'qda')\n",
    "    qda_accuracies.append(acc)\n",
    "printlist(qda_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression: accuracy ~ total-variance-explained\n",
    "logreg_accuracies=[]\n",
    "for i in range(15):\n",
    "    acc = score(X_train_list[i],X_test_list[i],y_train,y_test,'logreg')\n",
    "    logreg_accuracies.append(acc)\n",
    "printlist(logreg_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=plt.subplot(111)\n",
    "plt.plot(var_ladder,lda_accuracies,label=\"lda\")\n",
    "plt.plot(var_ladder,qda_accuracies,label=\"qda\")\n",
    "plt.plot(var_ladder,logreg_accuracies,label=\"logreg\")\n",
    "leg = plt.legend(loc=4, ncol=1, shadow=False, fancybox=False)\n",
    "leg.get_frame().set_alpha(0.5)\n",
    "plt.title(\"classification accuracy on PCA dimensionality reduced data\")\n",
    "plt.xlabel('total variance explained')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(svd_solver='randomized',whiten=True)\n",
    "pca.fit(X_train)\n",
    "var=np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"best number of dimension: \" + str(np.argwhere(var>0.75)[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension reduction using PCA, code ref: https://www.kaggle.com/ddmngml/pca-and-svm-on-mnist-dataset\n",
    "\n",
    "n_components = 33\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',whiten=True).fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pca.explained_variance_ratio_, bins=n_components, log=True)\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA-LDA\n",
    "classify(X_train_pca, X_test_pca, y_train, y_test, 'lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA-QDA\n",
    "classify(X_train_pca, X_test_pca, y_train, y_test, 'qda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA-logistic regression\n",
    "classify(X_train_pca, X_test_pca, y_train, y_test, 'logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
